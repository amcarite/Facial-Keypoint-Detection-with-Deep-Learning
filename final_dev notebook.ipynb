{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Final Project - Facial Keypoint Recognition \n",
    "#### Alex Carite | Oscar Linares | Greg Rosen | Shehzad Shahbuddin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "\n",
    "import time\n",
    "import os.path\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from random import randrange\n",
    "from math import sin, cos, pi\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, GlobalAveragePooling2D, LeakyReLU, BatchNormalization, RandomFlip, RandomRotation\n",
    "from tensorflow.keras import optimizers, Input, Model\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.applications import ResNet50, ResNet50V2\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7, EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B3\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "print (\"OK\")\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking to see if the train/test csv are loaded, if not, unzip from dir\n",
    "if (os.path.exists('training.csv') == False):\n",
    "    !unzip training.zip\n",
    "else:\n",
    "    print('training data already unzipped')\n",
    "\n",
    "if (os.path.exists('test.csv') == False):\n",
    "    !unzip test.zip\n",
    "else:\n",
    "    print('test data already unzipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv('training.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for data shapes\n",
    "def two_dim(image):\n",
    "    'takes in an image vector of 9,216 pixels and makes it into a 96x96 shape'\n",
    "    return np.array(image.split(' '), dtype=int).reshape(96, 96)\n",
    "\n",
    "def make_array(image):\n",
    "    return np.array(image.split(' '), dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transform all data\n",
    "X = np.array([two_dim(train.Image[i]) for i in range(len(train))])\n",
    "\n",
    "X = X / 255.0\n",
    "Y = np.array([train.drop('Image', axis = 1).iloc[i] for i in range(len(train))])\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "train_data, train_labels = X[:5000], Y[:5000]\n",
    "mini_train_data, mini_train_labels = X[:1000], Y[:1000]\n",
    "dev_data, dev_labels = X[5000:], Y[5000:]\n",
    "numFeatures = train_data[1].size\n",
    "numTrainExamples = train_data.shape[0]\n",
    "numMiniExamples = mini_train_data.shape[0]\n",
    "numDevExamples = dev_data.shape[0]\n",
    "print(f'Train examples {numTrainExamples}')\n",
    "print(f'Train features {numFeatures}')\n",
    "print(f'mini_Train examples {numMiniExamples}')\n",
    "print(f'Dev examples {numDevExamples}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for data shapes\n",
    "def two_dim(image):\n",
    "    'takes in an image vector of 9,216 pixels and makes it into a 96x96 shape'\n",
    "    return np.array(image.split(' '), dtype=int).reshape(96, 96)\n",
    "\n",
    "def make_array(image):\n",
    "    return np.array(image.split(' '), dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view missing values\n",
    "import missingno as msno\n",
    "fig, ax = plt.subplots()\n",
    "msno.bar(train)\n",
    "ax.set_title(\"Missing Values\", fontsize = 30, pad = 20)\n",
    "ax.set_xlabel(\"Feature\", fontsize = 25, labelpad = 20)\n",
    "ax.set_ylabel(\"Fill Rate\", fontsize = 25, labelpad = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EDA see percentage of na's for each column in the training dataset\n",
    "train.isna().sum()/len(train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#continue EDA, see distribution of all coordinates in train data except the \"Image\" column\n",
    "train.hist(bins = 30, figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Remove the Missing Values\n",
    "- We lose 70% of the dataset when removing NAs\n",
    "- We will also create a dataset with imputing the labels with forward ffill. This will get us more data, but likely less accurate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NAs from train and split into training and dev\n",
    "train_noNA_temp = train.dropna()\n",
    "dev_set = train_noNA_temp[:500]\n",
    "train_noNA = train_noNA_temp[500:]\n",
    "\n",
    "#From the complete train set, drop the rows which will be included in the dev set\n",
    "cond = train['Image'].isin(dev_set['Image'])\n",
    "train.drop(train[cond].index, inplace = True)\n",
    "\n",
    "#Create a ffill set based off the training data \n",
    "train_ffill = train.fillna(method='ffill')\n",
    "\n",
    "def load_images(image_data):\n",
    "    images = []\n",
    "    for idx, sample in image_data.iterrows():\n",
    "        image = np.array(sample['Image'].split(' '), dtype=int)\n",
    "        image = np.reshape(image, (96,96,1))\n",
    "        images.append(image)\n",
    "    images = np.array(images)/255.\n",
    "    return images\n",
    "\n",
    "def load_labels(label_data):\n",
    "    label_data = label_data.drop(['Image'], axis=1)\n",
    "    label_features = []\n",
    "    for idx, features in label_data.iterrows():\n",
    "        label_features.append(features)\n",
    "    label_features = np.array(label_features, dtype=float)\n",
    "    return label_features\n",
    "\n",
    "\n",
    "#Set of full data with ffill for missing labels\n",
    "train_data_ffill  = load_images(train_ffill)\n",
    "train_labels_ffill = load_labels(train_ffill)\n",
    "\n",
    "\n",
    "#Dataset with only no NA rows\n",
    "train_data_noNA  = load_images(train_noNA)\n",
    "train_labels_noNA = load_labels(train_noNA)\n",
    "\n",
    "\n",
    "#Dev set for testing \n",
    "dev_data = load_images(dev_set)\n",
    "dev_labels = load_labels(dev_set)\n",
    "\n",
    "\n",
    "#Test images for Kaggle competition \n",
    "test_images = load_images(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viusalizing the Images and Facial Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function for showing images\n",
    "def show_images(data, labels, num_examples=3):\n",
    "  \n",
    "  #transform data  into 2D matrix\n",
    "  X2D = np.reshape(data, (-1, 96, 96))\n",
    "\n",
    "  num = num_examples * 3\n",
    "  count = 0\n",
    "\n",
    "  #create a figure \n",
    "  fig, axes = plt.subplots(num_examples, 3, figsize = (9.6, 9.6))\n",
    "\n",
    "\n",
    "  #iterate across the row of images and display one image in each of the num_examples boxes\n",
    "  for n in range(num):\n",
    "      ax = axes[count//num_examples, count%num_examples]\n",
    "      rand = randrange(0, len(data))\n",
    "      ax.imshow(X2D[rand], cmap = 'gray')\n",
    "      count += 1\n",
    "      for loc in range(0, len(labels[n]), 2):\n",
    "          ax.plot(labels[rand][loc], labels[rand][loc+1], '*r')\n",
    "      \n",
    "  plt.tight_layout()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Images without all labeled points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#explore some of the images in the training data\n",
    "show_images(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View images with all labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Same analysis as above but with the noNA dataset - notice the how all the features are marked on the face\n",
    "show_images(train_data_noNA, train_labels_noNA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View images with forward filled points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(train_data_ffill, train_labels_ffill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- while many of the ffill labels are close to the correct location, there is still a bit of discrepancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at removing outliers\n",
    "# train_outliers  = train[((train['left_eye_inner_corner_x'] - train['left_eye_inner_corner_x'].mean()) / train['left_eye_inner_corner_x'].std()).abs() < 3]\n",
    "# train_outliers = train[train.apply(lambda x: np.abs(x - x.mean()) / x.std() < 3).all(axis=1)]\n",
    "# train_outliers.hist(bins = 30, figsize=(15,15))\n",
    "# plt.show()\n",
    "\n",
    "#create df for noNA data to do the same analysis as above\n",
    "# tempdf = pd.DataFrame(train_labels_noNA)\n",
    "# tempdf.hist(bins = 30, figsize=(15,15))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Confirm size of the datasets\n",
    "print(train_data_noNA.shape)\n",
    "print(train_labels_noNA.shape)\n",
    "print(train_data_ffill.shape)\n",
    "print(train_labels_ffill.shape)\n",
    "print(dev_data.shape)\n",
    "print(dev_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define image augmentation functions\n",
    "def rotate_augmentation(images, keypoints, angles):\n",
    "    rotated_images = []\n",
    "    rotated_keypoints = []\n",
    "    for angle in angles:    # Rotation augmentation for a list of angle values\n",
    "        for angle in [angle,-angle]:\n",
    "            rotation_matrix = cv2.getRotationMatrix2D((48,48), angle, 1.0)\n",
    "            angle_rad = -angle*pi/180.     # Obtain angle in radians from angle in degrees (notice negative sign for change in clockwise vs anti-clockwise directions from conventional rotation to cv2's image rotation)\n",
    "            # rotate images\n",
    "            for image in images:\n",
    "                rotated_image = cv2.warpAffine(image, rotation_matrix, (96,96), flags=cv2.INTER_CUBIC)\n",
    "                rotated_images.append(rotated_image)\n",
    "            rotated_images_reshaped = np.reshape(rotated_images, (-1,96,96,1))\n",
    "            # rotate keypoints\n",
    "            for keypoint in keypoints:\n",
    "                rotated_keypoint = keypoint - 48.    # Subtract the middle value of the image dimension\n",
    "                for idx in range(0, len(rotated_keypoint), 2):\n",
    "                    # https://in.mathworks.com/matlabcentral/answers/93554-how-can-i-rotate-a-set-of-points-in-a-plane-by-a-certain-angle-about-an-arbitrary-point\n",
    "                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n",
    "                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n",
    "                rotated_keypoint += 48.   # Add the earlier subtracted value\n",
    "                rotated_keypoints.append(rotated_keypoint)\n",
    "            rotated_keypoints_reshaped = np.reshape(rotated_keypoints, (-1, 30))\n",
    "    return rotated_images_reshaped, rotated_keypoints_reshaped\n",
    "\n",
    "def alter_brightness(images, keypoints, increase_factor=1.2, decrease_factor=0.6):\n",
    "    altered_brightness_images = []\n",
    "    inc_brightness_images = np.clip(images*increase_factor, 0.0, 1.0)    # Increased brightness & clip any values outside the range of [-1,1]\n",
    "    dec_brightness_images = np.clip(images*decrease_factor, 0.0, 1.0)    # Decreased brightness & clip any values outside the range of [-1,1]\n",
    "    altered_brightness_images.extend(inc_brightness_images)\n",
    "    altered_brightness_images.extend(dec_brightness_images)\n",
    "    altered_brightness_images_reshaped = np.reshape(altered_brightness_images, (-1,96,96,1))\n",
    "    altered_brightness_keypoints_reshaped = np.reshape(np.concatenate((keypoints, keypoints)), (-1, 30))\n",
    "    return altered_brightness_images_reshaped, altered_brightness_keypoints_reshaped\n",
    "\n",
    "def shift_images(images, keypoints, pixel_shifts):\n",
    "    shifted_images = []\n",
    "    shifted_keypoints = []\n",
    "    for shift in pixel_shifts:    # Augmenting over several pixel shift values\n",
    "        for (shift_x,shift_y) in [(-shift,-shift),(-shift,shift),(shift,-shift),(shift,shift)]:\n",
    "            shift_matrix = np.float32([[1,0,shift_x],[0,1,shift_y]])\n",
    "            for image, keypoint in zip(images, keypoints):\n",
    "                shifted_image = cv2.warpAffine(image, shift_matrix, (96,96), flags=cv2.INTER_CUBIC)\n",
    "                shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n",
    "                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<96.0):\n",
    "                    shifted_images.append(shifted_image.reshape(96,96,1))\n",
    "                    shifted_keypoints.append(shifted_keypoint)\n",
    "    shifted_images_reshaped = np.reshape(shifted_images, (-1,96,96,1))\n",
    "    shifted_keypoints = np.clip(shifted_keypoints,0.0,96.0)\n",
    "    shifted_keypoints_reshaped = np.reshape(shifted_keypoints, (-1, 30))\n",
    "    return shifted_images_reshaped, shifted_keypoints_reshaped\n",
    "\n",
    "def add_random_noise(images, keypoints, noise_factor=0.008):\n",
    "    noisy_images = []\n",
    "    for image in images:\n",
    "        noisy_image = cv2.add(image, noise_factor*np.random.randn(96,96,1))    # Adding random normal noise to the input image & clip the resulting noisy image between [-1,1]\n",
    "        noisy_images.append(noisy_image.reshape(96,96,1))\n",
    "    noisy_images_reshaped = np.reshape(noisy_images, (-1,96,96,1))\n",
    "    return noisy_images_reshaped, keypoints\n",
    "\n",
    "def guassian_blur(images, keypoints, kernel=(5,5)):\n",
    "    blurred_images = []\n",
    "    for image in images:\n",
    "        dst = cv2.GaussianBlur(image, kernel, cv2.BORDER_DEFAULT)\n",
    "        blurred_image = dst.reshape(96,96,1)\n",
    "        blurred_images.append(blurred_image)\n",
    "    blurred_images_reshaped = np.reshape(blurred_images, (-1,96,96,1))\n",
    "    return blurred_images_reshaped, keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate images and keypoints\n",
    "train_data_rotated, train_labels_rotated = rotate_augmentation(train_data_noNA, train_labels_noNA, [12])\n",
    "\n",
    "# alter brightness\n",
    "train_data_brightness, train_labels_brightness = alter_brightness(\n",
    "                                                        train_data_noNA,\n",
    "                                                        train_labels_noNA,\n",
    "                                                        increase_factor=1.2,\n",
    "                                                        decrease_factor=0.6\n",
    "                                                    )\n",
    "\n",
    "# shift images and keypoints\n",
    "train_data_shifted, train_labels_shifted = shift_images(train_data_noNA, train_labels_noNA, [12])\n",
    "\n",
    "# add random noise\n",
    "train_data_noise, train_labels_noise = add_random_noise(train_data_noNA, train_labels_noNA, 0.03)\n",
    "\n",
    "# apply gaussian blur\n",
    "train_data_blurred, train_labels_blurred = guassian_blur(train_data_noNA, train_labels_noNA, kernel=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all augmented data\n",
    "train_data_aug = np.concatenate(\n",
    "    (train_data_noNA, train_data_rotated, train_data_shifted, train_data_brightness, train_data_noise, train_data_blurred)\n",
    ")\n",
    "\n",
    "train_labels_aug = np.concatenate(\n",
    "    (train_labels_noNA, train_labels_rotated, train_labels_shifted, train_labels_brightness, train_labels_noise, train_labels_blurred)\n",
    ")\n",
    "\n",
    "print(train_data_aug.shape)\n",
    "print(train_labels_aug.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing Same Augmentation on FFill label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate images and keypoints\n",
    "train_data_ffill_rotated, train_labels_ffill_rotated = rotate_augmentation(train_data_ffill, train_labels_ffill, [12])\n",
    "\n",
    "# alter brightness\n",
    "train_data_ffill_brightness, train_labels_ffill_brightness = alter_brightness(\n",
    "                                                        train_data_ffill,\n",
    "                                                        train_labels_ffill,\n",
    "                                                        increase_factor=1.2,\n",
    "                                                        decrease_factor=0.6\n",
    "                                                    )\n",
    "\n",
    "# shift images and keypoints\n",
    "train_data_ffill_shifted, train_labels_ffill_shifted = shift_images(train_data_ffill, train_labels_ffill, [12])\n",
    "\n",
    "# add random noise\n",
    "train_data_ffill_noise, train_labels_ffill_noise = add_random_noise(train_data_ffill, train_labels_ffill, 0.03)\n",
    "\n",
    "# apply gaussian blur\n",
    "train_data_ffill_blurred, train_labels_ffill_blurred = guassian_blur(train_data_ffill, train_labels_ffill, kernel=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all augmented data\n",
    "train_data_ffill_aug = np.concatenate(\n",
    "    (train_data_ffill, train_data_ffill_rotated, train_data_ffill_shifted, train_data_ffill_brightness, train_data_ffill_noise, train_data_ffill_blurred)\n",
    ")\n",
    "\n",
    "train_labels_ffill_aug = np.concatenate(\n",
    "    (train_labels_ffill, train_labels_ffill_rotated, train_labels_ffill_shifted, train_labels_ffill_brightness, train_labels_ffill_noise, train_labels_ffill_blurred)\n",
    ")\n",
    "\n",
    "print(train_data_ffill_aug.shape)\n",
    "print(train_labels_ffill_aug.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlyStopping = EarlyStopping(monitor='loss', patience=30, mode='min',\n",
    "                             baseline=None)\n",
    "\n",
    "rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=5, min_lr=1e-15, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape tuples for reshaping the data for model\n",
    "train_reshape = (5000, 9216)\n",
    "train_noNA_reshape = (1200, 9216)\n",
    "dev_reshape = (2049, 9216)\n",
    "dev_noNA_reshape = (940, 9216)\n",
    "label_reshape= (-1, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "- creating a perceptron model with a single hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # baseline model\n",
    "# model_base = Sequential()\n",
    "# # model_base.add(Dense(units=512, activation='softmax'))\n",
    "# model_base.add(Dense(units=30, activation='softmax'))\n",
    "\n",
    "# model_base.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# start_time_base = time.time()\n",
    "# history = model_base.fit(train_data_noNA.reshape(-1,96*96), train_labels_noNA, shuffle=True, batch_size=1, verbose=0, epochs=20)\n",
    "# train_time_base = time.time() - start_time_base\n",
    "# print ('Train time = ', train_time_base)\n",
    "# score_base = model_base.evaluate(dev_data.reshape(-1, 96*96), dev_labels, verbose=0) \n",
    "# print('Test score:', score_base[0]) \n",
    "# print('Test accuracy:', score_base[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Value Records Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # No NA model\n",
    "# model_NN_noNA1 = Sequential()\n",
    "# # model_NN_noNA1.add(Dense(30, input_dim=9216, activation='sigmoid'))\n",
    "# # model_NN_noNA1.add(Dense(30, input_dim=30, activation='sigmoid'))\n",
    "# model_NN_noNA1.add(Dense(units=30, input_dim=9216, activation='softmax'))\n",
    "\n",
    "# sgd = optimizers.SGD(lr=0.01)\n",
    "# model_NN_noNA1.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# start_time_noNA1 = time.time()\n",
    "# history = model_NN_noNA1.fit(train_data_noNA.reshape(train_noNA_reshape), train_labels_noNA, shuffle=False, batch_size=1, verbose=0, epochs=10) \n",
    "# train_time_noNA1 = time.time() - start_time_noNA1\n",
    "# score_NN_noNA1 = model_NN_noNA1.evaluate(dev_data_noNA.reshape(dev_noNA_reshape), dev_labels_noNA, verbose=0) \n",
    "# print('Test score:', score_NN_noNA1[0]) \n",
    "# print('Test accuracy:', score_NN_noNA1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because baseline performance is higher on the missing-value-removed model, and the filled values on the missing-value records are inaccurate, we will proceed with iterating on the no-na model (or maybe we will add an additional label that specifies which records had imputed values) so the model can take that into consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Model Baseline Attempt (FFILL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#build archetecture\n",
    "model_CNN_ffill1 = Sequential() \n",
    "model_CNN_ffill1.add(Conv2D(64, kernel_size=(3, 3),activation='relu',input_shape=(96, 96, 1)))\n",
    "model_CNN_ffill1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_CNN_ffill1.add(Dropout(0.5))\n",
    "model_CNN_ffill1.add(Flatten())\n",
    "model_CNN_ffill1.add(Dense(96))\n",
    "model_CNN_ffill1.add(BatchNormalization())\n",
    "model_CNN_ffill1.add(Activation('relu'))\n",
    "model_CNN_ffill1.add(Dense(30))\n",
    "\n",
    "model_CNN_ffill1.summary()\n",
    "model_CNN_ffill1.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "#Train the model\n",
    "start_time_CNN_ffill1 = time.time()\n",
    "history_CNN_ffill1 = model_CNN_ffill1.fit(train_data_ffill, train_labels_ffill, batch_size=64, epochs=100, validation_data=(dev_data, dev_labels), shuffle = True, callbacks=[earlyStopping, rlp])\n",
    "train_time_CNN_ffill1 = time.time() - start_time_CNN_ffill1\n",
    "\n",
    "#Save the model for later use\n",
    "model_CNN_ffill1.save_weights('models/model_CNN_ffill1')\n",
    "\n",
    "##Load model weights if already trained\n",
    "#model_CNN_ffill1.load_weights('models/model_CNN_ffill1')\n",
    "\n",
    "#Score the model\n",
    "score_CNN_ffill1 = model_CNN_ffill1.evaluate(dev_data, dev_labels, verbose=0)\n",
    "print('Test score:', score_CNN_ffill1[0]) \n",
    "print('Test accuracy:', score_CNN_ffill1[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "df = pd.DataFrame(history_CNN_ffill1.history)\n",
    "df[['loss', 'val_loss']].plot(ax=ax[0])\n",
    "df[['accuracy', 'val_accuracy']].plot(ax=ax[1])\n",
    "ax[0].set_title('Model Loss', fontsize=12)\n",
    "ax[1].set_title('Model Acc', fontsize=12)\n",
    "fig.suptitle('Model Metrics', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same CNN as before, but training with the noNA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Model Architecture\n",
    "model_CNN_noNA1 = Sequential() \n",
    "model_CNN_noNA1.add(Conv2D(64, kernel_size=(3, 3),activation='relu',input_shape=(96, 96, 1)))\n",
    "model_CNN_noNA1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_CNN_noNA1.add(Dropout(0.2))\n",
    "model_CNN_noNA1.add(Flatten())\n",
    "model_CNN_noNA1.add(Dense(96))\n",
    "model_CNN_noNA1.add(BatchNormalization())\n",
    "model_CNN_noNA1.add(Activation('relu'))\n",
    "model_CNN_noNA1.add(Dense(30))\n",
    "\n",
    "model_CNN_noNA1.summary()\n",
    "model_CNN_noNA1.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Train Model\n",
    "start_time_CNN_noNA1 = time.time()\n",
    "history_CNN_noNA1 = model_CNN_noNA1.fit(train_data_noNA, train_labels_noNA, batch_size=64, epochs=100, validation_data=(dev_data, dev_labels), shuffle = True, callbacks=[earlyStopping, rlp])\n",
    "train_time_CNN_noNA1 = time.time() - start_time_CNN_noNA1\n",
    "\n",
    "#save model\n",
    "model_CNN_noNA1.save_weights('models/model_CNN_noNA1')\n",
    "\n",
    "##Load model weights if already trained\n",
    "#model_CNN_noNA1.load_weights('models/model_CNN_noNA1')\n",
    "\n",
    "#evaluate the model\n",
    "score_CNN_noNA1 = model_CNN_noNA1.evaluate(dev_data, dev_labels)\n",
    "print('Test score:', score_CNN_noNA1[0]) \n",
    "print('Test accuracy:', score_CNN_noNA1[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "df = pd.DataFrame(history_CNN_noNA1.history)\n",
    "df[['loss', 'val_loss']].plot(ax=ax[0])\n",
    "df[['accuracy', 'val_accuracy']].plot(ax=ax[1])\n",
    "ax[0].set_title('Model Loss', fontsize=12)\n",
    "ax[1].set_title('Model Acc', fontsize=12)\n",
    "fig.suptitle('Model Metrics', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning with Resnet50: CNN with Pre-trained Resnet and one dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet_noNA_D1 = Sequential() \n",
    "pretrained_model = ResNet50(input_shape=(96,96,3), include_top=False, weights='imagenet')\n",
    "pretrained_model.trainable = True\n",
    "\n",
    "#Build Model\n",
    "model_resnet_noNA_D1.add(Conv2D(3, kernel_size=(1, 1), activation='relu', padding= 'same' ,input_shape=(96, 96, 1)))\n",
    "model_resnet_noNA_D1.add(LeakyReLU(alpha=0.1))\n",
    "model_resnet_noNA_D1.add(pretrained_model)\n",
    "model_resnet_noNA_D1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_resnet_noNA_D1.add(Dropout(0.1))\n",
    "model_resnet_noNA_D1.add(Flatten())\n",
    "model_resnet_noNA_D1.add(Dense(30))\n",
    "model_resnet_noNA_D1.summary()\n",
    "\n",
    "model_resnet_noNA_D1.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model \n",
    "start_time_resnet_noNA_D1 = time.time()\n",
    "history_resnet_noNA_D1 = model_resnet_noNA_D1.fit(train_data_noNA, train_labels_noNA, batch_size=64, epochs=100, validation_data=(dev_data, dev_labels), shuffle = True, callbacks=[earlyStopping, rlp])\n",
    "train_time_resnet_noNA_D1 = time.time() - start_time_resnet_noNA_D1\n",
    "\n",
    "#Save model\n",
    "model_resnet_noNA_D1.save_weights('models/model_resnet_noNA_D1')\n",
    "\n",
    "##Load model weights if already trained\n",
    "#model_resnet_noNA_D1.load_weights('models/model_resnet_noNA_D1')\n",
    "\n",
    "score_resnet_noNA_D1 = model_resnet_noNA_D1.evaluate(dev_data, dev_labels)\n",
    "print('Test score:', score_resnet_noNA_D1[0]) \n",
    "print('Test accuracy:', score_resnet_noNA_D1[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "df = pd.DataFrame(history_resnet_noNA_D1.history)\n",
    "df[['loss', 'val_loss']].plot(ax=ax[0])\n",
    "df[['accuracy', 'val_accuracy']].plot(ax=ax[1])\n",
    "ax[0].set_title('Model Loss', fontsize=12)\n",
    "ax[1].set_title('Model Acc', fontsize=12)\n",
    "fig.suptitle('Model Metrics', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet pretrained with two dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build resnet model\n",
    "model_resnet_noNA_D2 = Sequential() \n",
    "pretrained_model = ResNet50(input_shape=(96,96,3), include_top=False, weights='imagenet')\n",
    "pretrained_model.trainable = True\n",
    "\n",
    "#Build Model Architecture\n",
    "model_resnet_noNA_D2.add(Conv2D(3, kernel_size=(1, 1), activation='relu', padding= 'same' ,input_shape=(96, 96, 1)))\n",
    "model_resnet_noNA_D2.add(LeakyReLU(alpha=0.1))\n",
    "model_resnet_noNA_D2.add(pretrained_model)\n",
    "model_resnet_noNA_D2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_resnet_noNA_D2.add(Dropout(0.1))\n",
    "model_resnet_noNA_D2.add(Flatten())\n",
    "model_resnet_noNA_D2.add(Dense(96))\n",
    "model_resnet_noNA_D2.add(Dense(30))\n",
    "\n",
    "model_resnet_noNA_D2.summary()\n",
    "\n",
    "model_resnet_noNA_D2.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "start_time_resnet_noNA_D2 = time.time()\n",
    "history_resnet_noNA_D2 = model_resnet_noNA_D2.fit(train_data_noNA, train_labels_noNA, batch_size=64, epochs=100, validation_data=(dev_data, dev_labels), shuffle = True, callbacks=[earlyStopping, rlp])\n",
    "train_time_resnet_noNA_D2 = time.time() - start_time_resnet_noNA_D2\n",
    "\n",
    "#Save Model\n",
    "model_resnet_noNA_D2.save_weights('models/model_resnet_noNA_D2')\n",
    "\n",
    "##Load model weights if already trained\n",
    "#model_resnet_noNA_D2.load_weights('models/model_resnet_noNA_D2')\n",
    "\n",
    "#Evaluate Model\n",
    "score_resnet_noNA_D2 = model_resnet_noNA_D2.evaluate(dev_data, dev_labels)\n",
    "print('Test score:', score_resnet_noNA_D2[0]) \n",
    "print('Test accuracy:', score_resnet_noNA_D2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "df = pd.DataFrame(history_resnet_noNA_D2.history)\n",
    "df[['loss', 'val_loss']].plot(ax=ax[0])\n",
    "df[['accuracy', 'val_accuracy']].plot(ax=ax[1])\n",
    "ax[0].set_title('Model Loss', fontsize=12)\n",
    "ax[1].set_title('Model Acc', fontsize=12)\n",
    "fig.suptitle('Model Metrics', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResnetV2 With lots of Dense Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build resnet model\n",
    "model_resnet_noNA_C1D4 = Sequential() \n",
    "pretrained_model = ResNet50V2(input_shape=(96,96,3), include_top=False, weights='imagenet')\n",
    "pretrained_model.trainable = True\n",
    "\n",
    "#Build Model Architecture\n",
    "model_resnet_noNA_C1D4.add(Conv2D(64, kernel_size=(2, 2), activation='relu', padding= 'same' ,input_shape=(96, 96, 1)))\n",
    "model_resnet_noNA_C1D4.add(LeakyReLU(alpha=0.2))\n",
    "model_resnet_noNA_C1D4.add(Conv2D(3, kernel_size=(1, 1), activation='relu', padding= 'same' ,input_shape=(96, 96, 64)))\n",
    "model_resnet_noNA_C1D4.add(LeakyReLU(alpha=0.1))\n",
    "model_resnet_noNA_C1D4.add(pretrained_model)\n",
    "model_resnet_noNA_C1D4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_resnet_noNA_C1D4.add(Dropout(0.1))\n",
    "model_resnet_noNA_C1D4.add(Flatten())\n",
    "model_resnet_noNA_C1D4.add(Dense(1024))\n",
    "model_resnet_noNA_C1D4.add(Dense(512))\n",
    "model_resnet_noNA_C1D4.add(Dense(96))\n",
    "model_resnet_noNA_C1D4.add(Dense(30))\n",
    "\n",
    "\n",
    "model_resnet_noNA_C1D4.summary()\n",
    "\n",
    "model_resnet_noNA_C1D4.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "start_time_resnet_noNA_C1D4 = time.time()\n",
    "history_resnet_noNA_C1D4 = model_resnet_noNA_C1D4.fit(train_data_noNA, train_labels_noNA, batch_size=64, epochs=100, validation_data=(dev_data, dev_labels), shuffle = True, callbacks=[earlyStopping, rlp])\n",
    "train_time_resnet_noNA_C1D4 = time.time() - start_time_resnet_noNA_C1D4\n",
    "\n",
    "#Save Model\n",
    "model_resnet_noNA_C1D4.save_weights('models/model_resnet_noNA_C1D4')\n",
    "\n",
    "##Load model weights if already trained\n",
    "#model_resnet_noNA_C1D4.load_weights('models/model_resnet_noNA_C1D4')\n",
    "\n",
    "score_resnet_noNA_C1D4 = model_resnet_noNA_C1D4.evaluate(dev_data, dev_labels)\n",
    "print('Test score:', score_resnet_noNA_C1D4[0]) \n",
    "print('Test accuracy:', score_resnet_noNA_C1D4[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "df = pd.DataFrame(history_resnet_noNA_C1D4.history)\n",
    "df[['loss', 'val_loss']].plot(ax=ax[0])\n",
    "df[['accuracy', 'val_accuracy']].plot(ax=ax[1])\n",
    "ax[0].set_title('Model Loss', fontsize=12)\n",
    "ax[1].set_title('Model Acc', fontsize=12)\n",
    "fig.suptitle('Model Metrics', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficient Net (1 Dense Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build effnet model\n",
    "model_effnetB7_noNA_D1 = Sequential() \n",
    "pretrained_model = EfficientNetB7(input_shape= (96, 96, 3), include_top= False, weights='imagenet')\n",
    "pretrained_model.trainable = True\n",
    "\n",
    "#Build Model Architecture\n",
    "model_effnetB7_noNA_D1.add(Conv2D(3, kernel_size=(1, 1), activation='relu', padding= 'same' ,input_shape=(96, 96, 1)))\n",
    "model_effnetB7_noNA_D1.add(LeakyReLU(alpha=0.1))\n",
    "model_effnetB7_noNA_D1.add(pretrained_model)\n",
    "model_effnetB7_noNA_D1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_effnetB7_noNA_D1.add(Dropout(0.1))\n",
    "model_effnetB7_noNA_D1.add(Flatten())\n",
    "model_effnetB7_noNA_D1.add(Dense(30))\n",
    "\n",
    "\n",
    "model_effnetB7_noNA_D1.summary()\n",
    "\n",
    "model_effnetB7_noNA_D1.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "start_time_effnetB7_noNA_D1 = time.time()\n",
    "history_effnetB7_noNA_D1 = model_effnetB7_noNA_D1.fit(train_data_noNA, train_labels_noNA, batch_size=64, epochs=100, validation_data=(dev_data, dev_labels), shuffle = True, callbacks=[earlyStopping, rlp])\n",
    "train_time_effnetB7_noNA_D1 = time.time() - start_time_effnetB7_noNA_D1\n",
    "\n",
    "#Save Model\n",
    "model_effnetB7_noNA_D1.save_weights('models/model_effnetB7_noNA_D1')\n",
    "\n",
    "##Load model weights if already trained\n",
    "#model_effnetB7_noNA_D1.load_weights('models/model_effnetB7_noNA_D1')\n",
    "\n",
    "score_effnetB7_noNA_D1 = model_effnetB7_noNA_D1.evaluate(dev_data, dev_labels)\n",
    "print('Test score:', score_effnetB7_noNA_D1[0]) \n",
    "print('Test accuracy:', score_effnetB7_noNA_D1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "df = pd.DataFrame(history_effnetB7_noNA_D1.history)\n",
    "df[['loss', 'val_loss']].plot(ax=ax[0])\n",
    "df[['accuracy', 'val_accuracy']].plot(ax=ax[1])\n",
    "ax[0].set_title('Model Loss', fontsize=12)\n",
    "ax[1].set_title('Model Acc', fontsize=12)\n",
    "fig.suptitle('Model Metrics', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet_v2B3 try number 2 (two conv, two dense, using Efficientnetv2_B3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build effnet model\n",
    "model_effnetV2B3_noNA_C2D2 = Sequential() \n",
    "pretrained_model = EfficientNetV2B3(input_shape= (96, 96, 3), include_top= False, weights='imagenet')\n",
    "pretrained_model.trainable = True\n",
    "\n",
    "#Build Model Architecture\n",
    "model_effnetV2B3_noNA_C2D2.add(Conv2D(24, kernel_size=(2, 2), activation='relu', padding= 'same' ,input_shape=(96, 96, 1)))\n",
    "model_effnetV2B3_noNA_C2D2.add(LeakyReLU(alpha=0.2))\n",
    "model_effnetV2B3_noNA_C2D2.add(Conv2D(3, kernel_size=(1, 1), activation='relu', padding= 'same' ,input_shape=(96, 96, 24)))\n",
    "model_effnetV2B3_noNA_C2D2.add(LeakyReLU(alpha=0.1))\n",
    "model_effnetV2B3_noNA_C2D2.add(pretrained_model)\n",
    "model_effnetV2B3_noNA_C2D2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_effnetV2B3_noNA_C2D2.add(Dropout(0.1))\n",
    "model_effnetV2B3_noNA_C2D2.add(Flatten())\n",
    "model_effnetV2B3_noNA_C2D2.add(Dense(90))\n",
    "model_effnetV2B3_noNA_C2D2.add(Dense(30))\n",
    "\n",
    "\n",
    "model_effnetV2B3_noNA_C2D2.summary()\n",
    "\n",
    "model_effnetV2B3_noNA_C2D2.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "start_time_effnetV2B3_noNA_C2D2 = time.time()\n",
    "history_effnetV2B3_noNA_C2D2 = model_effnetV2B3_noNA_C2D2.fit(train_data_noNA, train_labels_noNA, batch_size=64, epochs=100, validation_data=(dev_data, dev_labels), shuffle = True, callbacks=[earlyStopping, rlp])\n",
    "train_time_effnetV2B3_noNA_C2D2 = time.time() - start_time_effnetV2B3_noNA_C2D2\n",
    "\n",
    "#Save Model\n",
    "model_effnetV2B3_noNA_C2D2.save_weights('models/model_effnetV2B3_noNA_C2D2')\n",
    "\n",
    "##Load model weights if already trained\n",
    "#model_effnetV2B3_noNA_C2D2.load_weights('models/model_effnetV2B3_noNA_C2D2')\n",
    "\n",
    "#Evaluate Model\n",
    "score_effnetV2B3_noNA_C2D2 = model_effnetV2B3_noNA_C2D2.evaluate(dev_data, dev_labels)\n",
    "print('Test score:', score_effnetV2B3_noNA_C2D2[0]) \n",
    "print('Test accuracy:', score_effnetV2B3_noNA_C2D2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "df = pd.DataFrame(history_effnetV2B3_noNA_C2D2.history)\n",
    "df[['loss', 'val_loss']].plot(ax=ax[0])\n",
    "df[['accuracy', 'val_accuracy']].plot(ax=ax[1])\n",
    "ax[0].set_title('Model Loss', fontsize=12)\n",
    "ax[1].set_title('Model Acc', fontsize=12)\n",
    "fig.suptitle('Model Metrics', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50 with Augmented Data - Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Resnet model\n",
    "model_resnet_aug_D2 = Sequential() \n",
    "pretrained_model = ResNet50V2(input_shape=(96,96,3), include_top=False, weights='imagenet')\n",
    "pretrained_model.trainable = True\n",
    "\n",
    "#Build Model Architecture\n",
    "model_resnet_aug_D2.add(Conv2D(3, kernel_size=(1, 1), activation='relu', padding= 'same',  input_shape=(96, 96, 1)))\n",
    "model_resnet_aug_D2.add(LeakyReLU(alpha=0.1))\n",
    "model_resnet_aug_D2.add(pretrained_model)\n",
    "model_resnet_aug_D2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_resnet_aug_D2.add(Dropout(0.1))\n",
    "model_resnet_aug_D2.add(Flatten())\n",
    "model_resnet_aug_D2.add(Dense(96))\n",
    "model_resnet_aug_D2.add(Dense(30))\n",
    "\n",
    "\n",
    "model_resnet_aug_D2.summary()\n",
    "model_resnet_aug_D2.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "start_time_resnet_aug_D2 = time.time()\n",
    "history_resnet_aug_D2 = model_resnet_aug_D2.fit(train_data_aug, train_labels_aug, batch_size=64, epochs=100, validation_data=(dev_data, dev_labels), shuffle = True, callbacks=[earlyStopping, rlp])\n",
    "end_time_resnet_aug_D2 = time.time() - start_time_resnet_aug_D2\n",
    "\n",
    "#Save Model\n",
    "model_resnet_aug_D2.save_weights('models/model_resnet_aug_D2')\n",
    "\n",
    "##Load model weights if already trained\\\n",
    "#model_resnet_aug_D2.load_weights('models/model_resnet_aug_D2')\n",
    "\n",
    "\n",
    "score_resnet_aug_D2 = model_resnet_aug_D2.evaluate(dev_data, dev_labels)\n",
    "print('Test score:', score_resnet_aug_D2[0]) \n",
    "print('Test accuracy:', score_resnet_aug_D2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "df = pd.DataFrame(history_resnet_aug_D2.history)\n",
    "df[['loss', 'val_loss']].plot(ax=ax[0])\n",
    "df[['accuracy', 'val_accuracy']].plot(ax=ax[1])\n",
    "ax[0].set_title('Model Loss', fontsize=12)\n",
    "ax[1].set_title('Model Acc', fontsize=12)\n",
    "fig.suptitle('Model Metrics', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficientnet with Augmented data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Effnet model\n",
    "model_effnetB7_aug_D1 = Sequential() \n",
    "pretrained_model = EfficientNetB7(input_shape= (96, 96, 3), include_top= False, weights='imagenet')\n",
    "pretrained_model.trainable = True\n",
    "\n",
    "#Build Model Architecture\n",
    "model_effnetB7_aug_D1.add(Conv2D(3, kernel_size=(2, 2), activation='relu', padding= 'same' ,input_shape=(96, 96, 1)))\n",
    "model_effnetB7_aug_D1.add(LeakyReLU(alpha=0.1))\n",
    "model_effnetB7_aug_D1.add(pretrained_model)\n",
    "model_effnetB7_aug_D1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_effnetB7_aug_D1.add(Dropout(0.1))\n",
    "model_effnetB7_aug_D1.add(Flatten())\n",
    "model_effnetB7_aug_D1.add(Dense(30))\n",
    "\n",
    "\n",
    "model_effnetB7_aug_D1.summary()\n",
    "\n",
    "model_effnetB7_aug_D1.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "start_time_effnetB7_aug_D1 = time.time()\n",
    "history_effnetB7_aug_D1 = model_effnetB7_aug_D1.fit(train_data_aug, train_labels_aug, batch_size=64, epochs=80, validation_data=(dev_data, dev_labels), shuffle = True, callbacks=[earlyStopping, rlp])\n",
    "train_time_effnetB7_aug_D1 = time.time() - start_time_effnetB7_aug_D1\n",
    "\n",
    "\n",
    "#Evaluate Model\n",
    "score_effnetB7_aug_D1 = model_effnetB7_aug_D1.evaluate(dev_data, dev_labels)\n",
    "print('Test score:', score_effnetB7_aug_D1[0])\n",
    "print('Test accuracy:', score_effnetB7_aug_D1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetune\n",
    "pretrained_model.trainable = True\n",
    "model_effnetB7_aug_D1.summary()\n",
    "\n",
    "model_effnetB7_aug_D1.compile(\n",
    "    optimizer=Adam(1e-5),\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#Save Model\n",
    "model_effnetB7_aug_D1.save_weights('models/model_effnetB7_aug_D1')\n",
    "\n",
    "##Load model weights if already trained\n",
    "#model_effnetB7_aug_D1.load_weights('models/model_effnetB7_aug_D1')\n",
    "\n",
    "#Evaulate Model\n",
    "history_effnetB7_aug_D1 = model_effnetB7_aug_D1.fit(train_data_aug, train_labels_aug, batch_size=64, epochs=20, validation_data=(dev_data, dev_labels), shuffle = True, callbacks=[earlyStopping, rlp])\n",
    "score_resnet_aug_D1 = model_effnetB7_aug_D1.evaluate(dev_data, dev_labels)\n",
    "print('Test score:', score_resnet_aug_D1[0]) \n",
    "print('Test accuracy:', score_resnet_aug_D1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "df = pd.DataFrame(history_effnetB7_aug_D1.history)\n",
    "df[['loss', 'val_loss']].plot(ax=ax[0])\n",
    "df[['accuracy', 'val_accuracy']].plot(ax=ax[1])\n",
    "ax[0].set_title('Model Loss', fontsize=12)\n",
    "ax[1].set_title('Model Acc', fontsize=12)\n",
    "fig.suptitle('Model Metrics', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_lookup = pd.read_csv('IdLookupTable.csv')\n",
    "\n",
    "ImageId = list(id_lookup['ImageId']-1)\n",
    "RowId = list(id_lookup['RowId'])\n",
    "FeatureName = list(id_lookup['FeatureName'])\n",
    "feature_list = []\n",
    "for feature in FeatureName:\n",
    "    feature_list.append(FeatureName.index(feature))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(model, test_data, model_name):\n",
    "    #RowId,ImageId,FeatureName,Location\n",
    "    #Make Predictions \n",
    "    y_pred = model.predict(test_data)\n",
    "\n",
    "    predictions = []\n",
    "    for x,y in zip(ImageId, feature_list):\n",
    "        predictions.append(y_pred[x][y])\n",
    "        \n",
    "    row_ids = pd.Series(RowId, name = 'RowId')\n",
    "    locations = pd.Series(predictions, name = 'Location')\n",
    "    \n",
    "    #post processing step \n",
    "    locations = locations.clip(0.0,96.0)\n",
    "    submission_result = pd.concat([row_ids,locations],axis = 1)\n",
    "    submission_result.to_csv('eff_net_2', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adf783bbbd88482478cbb33b573058a9c80ad7e3b8253c9b953b19ddbee4c21"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
