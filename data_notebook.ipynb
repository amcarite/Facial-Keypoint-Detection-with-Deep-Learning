{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Datasets for Model Testing \n",
    "#### Alex Carite | Oscar Linares | Greg Rosen | Shehzad Shahbuddin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Tensorflow version 2.8.0\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "\n",
    "import time\n",
    "import os.path\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import matplotlib.pyplot as plt\n",
    "from random import randrange\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "np.random.seed(0)\n",
    "print (\"OK\")\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data already unzipped\n",
      "test data already unzipped\n"
     ]
    }
   ],
   "source": [
    "#Checking to see if the train/test csv are loaded, if not, unzip from dir\n",
    "if (os.path.exists('training.csv') == False):\n",
    "    !unzip training.zip\n",
    "else:\n",
    "    print('training data already unzipped')\n",
    "\n",
    "if (os.path.exists('test.csv') == False):\n",
    "    !unzip test.zip\n",
    "else:\n",
    "    print('test data already unzipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7049, 31)\n",
      "(1783, 2)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train = pd.read_csv('training.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to clean up a few NA's in our set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for data shapes\n",
    "def two_dim(image):\n",
    "    'takes in an image vector of 9,216 pixels and makes it into a 96x96 shape'\n",
    "    return np.array(image.split(' '), dtype=int).reshape(96, 96)\n",
    "\n",
    "def make_array(image):\n",
    "    return np.array(image.split(' '), dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples 5000\n",
      "Train features 9216\n",
      "mini_Train examples 1000\n",
      "Dev examples 2049\n"
     ]
    }
   ],
   "source": [
    "# transform all data\n",
    "X = np.array([two_dim(train.Image[i]) for i in range(len(train))])\n",
    "# X_tmp = X_tmp / 255.0\n",
    "# X = np.array([make_array(train.Image[i]) for i in range(len(train))])\n",
    "X = X / 255.0\n",
    "Y = np.array([train.drop('Image', axis = 1).iloc[i] for i in range(len(train))])\n",
    "\n",
    "#Need to make X_test and Y_test (will we have a Y_test? I think that may be handled in Kaggle)\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "train_data, train_labels = X[:5000], Y[:5000]\n",
    "mini_train_data, mini_train_labels = X[:1000], Y[:1000]\n",
    "dev_data, dev_labels = X[5000:], Y[5000:]\n",
    "numFeatures = train_data[1].size\n",
    "numTrainExamples = train_data.shape[0]\n",
    "numMiniExamples = mini_train_data.shape[0]\n",
    "numDevExamples = dev_data.shape[0]\n",
    "# numTestExamples = test_data.shape[0]\n",
    "print(f'Train examples {numTrainExamples}')\n",
    "print(f'Train features {numFeatures}')\n",
    "print(f'mini_Train examples {numMiniExamples}')\n",
    "print(f'Dev examples {numDevExamples}')\n",
    "# print(f'Test examples {numTestExamples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "7044     True\n",
       "7045     True\n",
       "7046    False\n",
       "7047    False\n",
       "7048     True\n",
       "Length: 7049, dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for duplicates \n",
    "train.duplicated(subset = ['Image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all NAs to have a clean fully labeled dataset\n",
    "train_noNA = train.dropna(axis=0, how='any', inplace = False)\n",
    "train_noNA = train_noNA.reset_index(drop=True)\n",
    "print(len(train))\n",
    "print(len(train_noNA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unlab = train[train.isnull().any(1)]\n",
    "train_unlab = train_unlab.reset_index(drop = True)\n",
    "print(len(train))\n",
    "print(len(train_unlab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create arrays for no-NA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform No NaN data\n",
    "X_noNA = np.array([two_dim(train_noNA.Image[i]) for i in range(len(train_noNA))])\n",
    "X_noNA = X_noNA / 255.0\n",
    "Y_noNA = np.array([train_noNA.drop('Image', axis = 1).iloc[i] for i in range(len(train_noNA))])\n",
    "\n",
    "\n",
    "shuffle_noNA = np.random.permutation(np.arange(X_noNA.shape[0]))\n",
    "X_noNA, Y_noNA = X_noNA[shuffle_noNA], Y_noNA[shuffle_noNA]\n",
    "train_data_noNA, train_labels_noNA = X_noNA[:1200], Y_noNA[:1200]\n",
    "dev_data_noNA, dev_labels_noNA = X_noNA[1200:], Y_noNA[1200:]\n",
    "numFeatures_noNA = train_data_noNA[1].size\n",
    "numTrainExamples_noNA = train_data_noNA.shape[0]\n",
    "numDevExamples_noNA = dev_data_noNA.shape[0]\n",
    "# numTestExamples = test_data.shape[0]\n",
    "print(f'Train examples {numTrainExamples_noNA}')\n",
    "print(f'Train features {numFeatures_noNA}')\n",
    "print(f'Dev examples {numDevExamples_noNA}')\n",
    "# print(f'Test examples {numTestExamples_noNA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform unlabeled data\n",
    "X_unlab = np.array([two_dim(train_unlab.Image[i]) for i in range(len(train_unlab))])\n",
    "X_unlab = X_unlab / 255.0\n",
    "Y_unlab = np.array([train_unlab.drop('Image', axis = 1).iloc[i] for i in range(len(train_unlab))])\n",
    "\n",
    "\n",
    "shuffle_unlab = np.random.permutation(np.arange(X_unlab.shape[0]))\n",
    "X_unlab, Y_unlab = X_unlab[shuffle_unlab], Y_unlab[shuffle_unlab]\n",
    "train_data_unlab, train_labels_unlab = X_unlab[:3000], Y_unlab[:3000]\n",
    "dev_data_unlab, dev_labels_unlab = X_unlab[3000:], Y_unlab[3000:]\n",
    "numFeatures_unlab = train_data_unlab[1].size\n",
    "numTrainExamples_unlab = train_data_unlab.shape[0]\n",
    "numDevExamples_unlab = dev_data_unlab.shape[0]\n",
    "# numTestExamples = test_data.shape[0]\n",
    "print(f'Train examples {numTrainExamples_unlab}')\n",
    "print(f'Train features {numFeatures_unlab}')\n",
    "print(f'Dev examples {numDevExamples_unlab}')\n",
    "# print(f'Test examples {numTestExamples_unlab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(X, y, n, plot_missing = False):\n",
    "    \"\"\"\n",
    "    plot n images with red dots for labels.\n",
    "    If plot_missing, plot images with missing values (useful for visualizing imputed labels)\"\"\"\n",
    "    if not plot_missing:\n",
    "        for i in range(n):\n",
    "            plt.imshow(X[i],cmap='gray')\n",
    "            #place a point for each of the pictures on the specified coordinates\n",
    "            for loc in range(0, len(y[i]),2):\n",
    "                plt.plot(y[i][loc], y[i][loc+1], '*r')\n",
    "            plt.show()\n",
    "        \n",
    "    elif plot_missing:\n",
    "        for i in train[train['left_eye_outer_corner_y'].isna()].index[:n]:\n",
    "            plt.imshow(X[i],cmap='gray')\n",
    "            #place a point for each of the pictures on the specified coordinates\n",
    "            for loc in range(0, len(y[i]),2):\n",
    "                plt.plot(y[i][loc], y[i][loc+1], '*r')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function for showing images\n",
    "def show_images(data, labels, num_examples=3):\n",
    "  \n",
    "  #transform data  into 2D matrix\n",
    "  X2D = np.reshape(data, (-1, 96, 96))\n",
    "\n",
    "  num = num_examples * 3\n",
    "  count = 0\n",
    "\n",
    "  #create a figure \n",
    "  fig, axes = plt.subplots(num_examples, 3, figsize = (9.6, 9.6))\n",
    "\n",
    "\n",
    "  #iterate across the row of images and display one image in each of the num_examples boxes\n",
    "  for n in range(num):\n",
    "      ax = axes[count//num_examples, count%num_examples]\n",
    "      rand = randrange(0, len(data))\n",
    "      ax.imshow(X2D[rand], cmap = 'gray')\n",
    "      count += 1\n",
    "      for loc in range(0, len(labels[n]), 2):\n",
    "          ax.plot(labels[n][loc], labels[n][loc+1], '*r')\n",
    "      \n",
    "  plt.tight_layout()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View some images with labeled points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#explore some of the images in the training data\n",
    "show_images(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View images without missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Same analysis as above but with the noNA dataset - notice the how all the features are marked on the face\n",
    "show_images(train_data_noNA, train_labels_noNA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that images with missing values are not as accurate as fully filled records, even for the values it has filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#continue EDA, see distribution of all coordinates in train data except the \"Image\" column\n",
    "train.hist(bins = 30, figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at removing outliers\n",
    "# train_outliers  = train[((train['left_eye_inner_corner_x'] - train['left_eye_inner_corner_x'].mean()) / train['left_eye_inner_corner_x'].std()).abs() < 3]\n",
    "train_outliers = train[train.apply(lambda x: np.abs(x - x.mean()) / x.std() < 3).all(axis=1)]\n",
    "train_outliers.hist(bins = 30, figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create df for noNA data to do the same analysis as above\n",
    "tempdf = pd.DataFrame(train_labels_noNA)\n",
    "tempdf.hist(bins = 30, figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Confirm size of the datasets\n",
    "print(train_data_noNA.shape)\n",
    "print(train_labels_noNA.shape)\n",
    "print(dev_data_noNA.shape)\n",
    "print(dev_labels_noNA.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (Keeping Missing Values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Fill Missing Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values\n",
    "train_ffill = train.fillna(method = \"ffill\")\n",
    "\n",
    "# transform Y for ffill in same way as non-ffill data (create for ffill imputation visuals)\n",
    "Y_ffill = np.array([train_ffill.drop('Image', axis = 1).iloc[i] for i in range(len(train_ffill))])\n",
    "Y_ffill = Y_ffill[shuffle]\n",
    "\n",
    "# transform train and dev labels for model\n",
    "train_labels_ffill = Y_ffill[:5000]\n",
    "dev_labels_ffill = Y_ffill[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Missing Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scale data (optimal for KNN distances)\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train.drop(columns = \"Image\"))\n",
    "train_labels_scaled = scaler.fit_transform(train_labels)\n",
    "# mini_train_labels_scaled = scaler.fit_transform(mini_train_labels)\n",
    "dev_labels_scaled = scaler.fit_transform(dev_labels)\n",
    "\n",
    "# KNN Imputation (scaled) (K = 5)\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "train_knn_scaled = imputer.fit_transform(train_scaled)\n",
    "train_labels_knn_scaled = imputer.fit_transform(train_labels_scaled)\n",
    "# mini_train_labels_knn_scaled = imputer.fit_transform(mini_train_labels_scaled)\n",
    "dev_labels_knn_scaled = imputer.fit_transform(dev_labels_scaled)\n",
    "\n",
    "### removing in lieu of scaled KNN\n",
    "# # KNN Imputation (no scale) (K = 5)\n",
    "# from sklearn.impute import KNNImputer\n",
    "# imputer = KNNImputer(n_neighbors=5)\n",
    "# train_knn = imputer.fit_transform(train.drop(columns=\"Image\"))\n",
    "# train_labels_knn = imputer.fit_transform(train_labels)\n",
    "# # mini_train_labels_knn = imputer.fit_transform(mini_train_labels)\n",
    "# dev_labels_knn = imputer.fit_transform(dev_labels)\n",
    "\n",
    "# Inverse transform after imputation for viewing performance on images\n",
    "train_knn_scaled_inverse = scaler.inverse_transform(train_knn_scaled)\n",
    "train_labels_knn_scaled_inverse = scaler.inverse_transform(train_labels_knn_scaled)\n",
    "# mini_train_labels_knn_scaled_inverse = scaler.inverse_transform(mini_train_labels_knn_scaled)\n",
    "dev_labels_knn_scaled_inverse = scaler.inverse_transform(dev_labels_knn_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm no more missing values (knn)\n",
    "import missingno as msno\n",
    "fig, ax = plt.subplots()\n",
    "msno.bar(pd.DataFrame(train_knn_scaled_inverse, columns = train.drop(columns = \"Image\").columns))\n",
    "ax.set_title(\"Missing Values after KNN\", fontsize = 30, pad = 20)\n",
    "ax.set_xlabel(\"Feature\", fontsize = 25, labelpad = 20)\n",
    "ax.set_ylabel(\"Fill Rate\", fontsize = 25, labelpad = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_mix = np.nan_to_num(train_labels, nan = -1) \n",
    "df = pd.DataFrame(train_labels_mix)\n",
    "df = df.round(2).astype(int)\n",
    "\n",
    "df_dev = pd.DataFrame(dev_labels_noNA)\n",
    "df_dev = df_dev.round(2).astype(int)\n",
    "\n",
    "feature_names = list(train.columns)[:30]\n",
    "\n",
    "df_1 = pd.DataFrame()\n",
    "\n",
    "for i in range(30):\n",
    "    model = LabelPropagation()\n",
    "    model.fit(train_data.reshape(train_reshape), df[i])\n",
    "    \n",
    "    new_labels = model.transduction_\n",
    "\n",
    "    df_1[feature_names[i]] = new_labels\n",
    "\n",
    "df_1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adf783bbbd88482478cbb33b573058a9c80ad7e3b8253c9b953b19ddbee4c21"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
